Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/10/26 17:13:40 INFO SparkContext: Running Spark version 2.0.0
16/10/26 17:13:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/10/26 17:13:40 WARN Utils: Your hostname, raghav resolves to a loopback address: 127.0.1.1; using 130.49.212.215 instead (on interface eth0)
16/10/26 17:13:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/10/26 17:13:40 INFO SecurityManager: Changing view acls to: raghav
16/10/26 17:13:40 INFO SecurityManager: Changing modify acls to: raghav
16/10/26 17:13:40 INFO SecurityManager: Changing view acls groups to: 
16/10/26 17:13:40 INFO SecurityManager: Changing modify acls groups to: 
16/10/26 17:13:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(raghav); groups with view permissions: Set(); users  with modify permissions: Set(raghav); groups with modify permissions: Set()
16/10/26 17:13:40 INFO Utils: Successfully started service 'sparkDriver' on port 43574.
16/10/26 17:13:41 INFO SparkEnv: Registering MapOutputTracker
16/10/26 17:13:41 INFO SparkEnv: Registering BlockManagerMaster
16/10/26 17:13:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1c01a913-bb9d-4712-a18d-e82c0c7c11dd
16/10/26 17:13:41 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
16/10/26 17:13:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/10/26 17:13:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
16/10/26 17:13:41 INFO Utils: Successfully started service 'SparkUI' on port 4041.
16/10/26 17:13:41 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://130.49.212.215:4041
16/10/26 17:13:41 INFO SparkContext: Added JAR file:/home/raghav/Documents/scalableMLBigData/A2/a2.jar at spark://130.49.212.215:43574/jars/a2.jar with timestamp 1477516421264
16/10/26 17:13:41 INFO Executor: Starting executor ID driver on host localhost
16/10/26 17:13:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53948.
16/10/26 17:13:41 INFO NettyBlockTransferService: Server created on 130.49.212.215:53948
16/10/26 17:13:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 130.49.212.215, 53948)
16/10/26 17:13:41 INFO BlockManagerMasterEndpoint: Registering block manager 130.49.212.215:53948 with 366.3 MB RAM, BlockManagerId(driver, 130.49.212.215, 53948)
16/10/26 17:13:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 130.49.212.215, 53948)
findmeee start code
16/10/26 17:13:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 145.5 KB, free 366.2 MB)
16/10/26 17:13:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.3 KB, free 366.1 MB)
16/10/26 17:13:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 130.49.212.215:53948 (size: 16.3 KB, free: 366.3 MB)
16/10/26 17:13:41 INFO SparkContext: Created broadcast 0 from textFile at a2.scala:34
findmeee convert to coordinate matrix
findmeee convert to indexed row matrix
16/10/26 17:13:42 INFO FileInputFormat: Total input paths to process : 1
16/10/26 17:13:42 INFO SparkContext: Starting job: reduce at CoordinateMatrix.scala:149
16/10/26 17:13:42 INFO DAGScheduler: Got job 0 (reduce at CoordinateMatrix.scala:149) with 2 output partitions
16/10/26 17:13:42 INFO DAGScheduler: Final stage: ResultStage 0 (reduce at CoordinateMatrix.scala:149)
16/10/26 17:13:42 INFO DAGScheduler: Parents of final stage: List()
16/10/26 17:13:42 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at CoordinateMatrix.scala:149), which has no missing parents
16/10/26 17:13:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
16/10/26 17:13:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2038.0 B, free 366.1 MB)
16/10/26 17:13:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 130.49.212.215:53948 (size: 2038.0 B, free: 366.3 MB)
16/10/26 17:13:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at CoordinateMatrix.scala:149)
16/10/26 17:13:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/10/26 17:13:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5445 bytes)
16/10/26 17:13:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5445 bytes)
16/10/26 17:13:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/10/26 17:13:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/10/26 17:13:42 INFO Executor: Fetching spark://130.49.212.215:43574/jars/a2.jar with timestamp 1477516421264
16/10/26 17:13:42 INFO TransportClientFactory: Successfully created connection to /130.49.212.215:43574 after 18 ms (0 ms spent in bootstraps)
16/10/26 17:13:42 INFO Utils: Fetching spark://130.49.212.215:43574/jars/a2.jar to /tmp/spark-eec5d6ad-4291-4396-a2ba-884229df8bdf/userFiles-8489cd61-9c5a-4ea9-b06e-0d14c6fa7b66/fetchFileTemp1079110293651066847.tmp
16/10/26 17:13:42 INFO Executor: Adding file:/tmp/spark-eec5d6ad-4291-4396-a2ba-884229df8bdf/userFiles-8489cd61-9c5a-4ea9-b06e-0d14c6fa7b66/a2.jar to class loader
16/10/26 17:13:42 INFO HadoopRDD: Input split: file:/home/raghav/Documents/scalableMLBigData/A2/small.csv:0+55005
16/10/26 17:13:42 INFO HadoopRDD: Input split: file:/home/raghav/Documents/scalableMLBigData/A2/small.csv:55005+55006
16/10/26 17:13:42 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/10/26 17:13:42 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/10/26 17:13:42 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/10/26 17:13:42 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/10/26 17:13:42 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
16/10/26 17:13:42 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 259.5 KB, free 365.9 MB)
16/10/26 17:13:42 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 260.0 KB, free 365.6 MB)
16/10/26 17:13:42 INFO BlockManagerInfo: Added rdd_1_0 in memory on 130.49.212.215:53948 (size: 259.5 KB, free: 366.0 MB)
16/10/26 17:13:42 INFO BlockManagerInfo: Added rdd_1_1 in memory on 130.49.212.215:53948 (size: 260.0 KB, free: 365.8 MB)
16/10/26 17:13:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1577 bytes result sent to driver
16/10/26 17:13:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1577 bytes result sent to driver
16/10/26 17:13:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 277 ms on localhost (1/2)
16/10/26 17:13:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 299 ms on localhost (2/2)
16/10/26 17:13:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/10/26 17:13:42 INFO DAGScheduler: ResultStage 0 (reduce at CoordinateMatrix.scala:149) finished in 0.310 s
16/10/26 17:13:42 INFO DAGScheduler: Job 0 finished: reduce at CoordinateMatrix.scala:149, took 0.414132 s
16/10/26 17:13:42 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:121
16/10/26 17:13:42 INFO DAGScheduler: Registering RDD 5 (map at CoordinateMatrix.scala:87)
16/10/26 17:13:42 INFO DAGScheduler: Got job 1 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
16/10/26 17:13:42 INFO DAGScheduler: Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
16/10/26 17:13:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
16/10/26 17:13:42 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at CoordinateMatrix.scala:87), which has no missing parents
16/10/26 17:13:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.5 KB, free 365.6 MB)
16/10/26 17:13:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.0 KB, free 365.6 MB)
16/10/26 17:13:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 130.49.212.215:53948 (size: 3.0 KB, free: 365.8 MB)
16/10/26 17:13:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at CoordinateMatrix.scala:87)
16/10/26 17:13:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/10/26 17:13:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5442 bytes)
16/10/26 17:13:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5442 bytes)
16/10/26 17:13:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/10/26 17:13:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/10/26 17:13:42 INFO BlockManager: Found block rdd_1_1 locally
16/10/26 17:13:42 INFO BlockManager: Found block rdd_1_0 locally
16/10/26 17:13:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1261 bytes result sent to driver
16/10/26 17:13:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1174 bytes result sent to driver
16/10/26 17:13:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (1/2)
16/10/26 17:13:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 69 ms on localhost (2/2)
16/10/26 17:13:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/10/26 17:13:42 INFO DAGScheduler: ShuffleMapStage 1 (map at CoordinateMatrix.scala:87) finished in 0.072 s
16/10/26 17:13:42 INFO DAGScheduler: looking for newly runnable stages
16/10/26 17:13:42 INFO DAGScheduler: running: Set()
16/10/26 17:13:42 INFO DAGScheduler: waiting: Set(ResultStage 2)
16/10/26 17:13:42 INFO DAGScheduler: failed: Set()
16/10/26 17:13:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at treeAggregate at RowMatrix.scala:121), which has no missing parents
16/10/26 17:13:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.1 KB, free 365.6 MB)
16/10/26 17:13:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 365.6 MB)
16/10/26 17:13:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 130.49.212.215:53948 (size: 3.9 KB, free: 365.8 MB)
16/10/26 17:13:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/10/26 17:13:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, ANY, 5197 bytes)
16/10/26 17:13:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, ANY, 5197 bytes)
16/10/26 17:13:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/10/26 17:13:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/10/26 17:13:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 4055 bytes result sent to driver
16/10/26 17:13:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 4055 bytes result sent to driver
16/10/26 17:13:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 93 ms on localhost (1/2)
16/10/26 17:13:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 95 ms on localhost (2/2)
16/10/26 17:13:42 INFO DAGScheduler: ResultStage 2 (treeAggregate at RowMatrix.scala:121) finished in 0.095 s
16/10/26 17:13:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/10/26 17:13:42 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
16/10/26 17:13:42 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
16/10/26 17:13:42 INFO DAGScheduler: Job 1 finished: treeAggregate at RowMatrix.scala:121, took 0.203315 s
16/10/26 17:13:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 130.49.212.215:53948 in memory (size: 3.9 KB, free: 365.8 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 130.49.212.215:53948 in memory (size: 3.0 KB, free: 365.8 MB)
16/10/26 17:13:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
16/10/26 17:13:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 365.6 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 365.6 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 365.8 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 4 from broadcast at RowMatrix.scala:439
16/10/26 17:13:43 INFO MapPartitionsRDD: Removing RDD 1 from persistence list
16/10/26 17:13:43 INFO BlockManager: Removing RDD 1
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.2 KB, free 366.1 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 270.0 B, free 366.1 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 130.49.212.215:53948 (size: 270.0 B, free: 366.3 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 5 from broadcast at RowMatrix.scala:439
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.1 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.1 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.3 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 6 from broadcast at RowMatrix.scala:439
findmeee0
16/10/26 17:13:43 INFO SparkContext: Starting job: first at IndexedRowMatrix.scala:57
16/10/26 17:13:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 159 bytes
16/10/26 17:13:43 INFO DAGScheduler: Got job 2 (first at IndexedRowMatrix.scala:57) with 1 output partitions
16/10/26 17:13:43 INFO DAGScheduler: Final stage: ResultStage 4 (first at IndexedRowMatrix.scala:57)
16/10/26 17:13:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
16/10/26 17:13:43 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:43 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at map at IndexedRowMatrix.scala:184), which has no missing parents
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 9.0 KB, free 366.1 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.3 KB, free 366.1 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 130.49.212.215:53948 (size: 4.3 KB, free: 366.3 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at map at IndexedRowMatrix.scala:184)
16/10/26 17:13:43 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
16/10/26 17:13:43 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5564 bytes)
16/10/26 17:13:43 INFO Executor: Running task 0.0 in stage 4.0 (TID 6)
16/10/26 17:13:43 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 62.0 KB, free 366.0 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added rdd_23_0 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.2 MB)
16/10/26 17:13:43 WARN Executor: 1 block locks were not released by TID = 6:
[rdd_23_0]
16/10/26 17:13:43 INFO Executor: Finished task 0.0 in stage 4.0 (TID 6). 2638 bytes result sent to driver
16/10/26 17:13:43 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 275 ms on localhost (1/1)
16/10/26 17:13:43 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
16/10/26 17:13:43 INFO DAGScheduler: ResultStage 4 (first at IndexedRowMatrix.scala:57) finished in 0.275 s
16/10/26 17:13:43 INFO DAGScheduler: Job 2 finished: first at IndexedRowMatrix.scala:57, took 0.288050 s
16/10/26 17:13:43 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:121
16/10/26 17:13:43 INFO DAGScheduler: Got job 3 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
16/10/26 17:13:43 INFO DAGScheduler: Final stage: ResultStage 6 (treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
16/10/26 17:13:43 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:43 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at treeAggregate at RowMatrix.scala:121), which has no missing parents
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.2 KB, free 366.0 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.0 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 130.49.212.215:53948 (size: 4.6 KB, free: 366.2 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:43 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
16/10/26 17:13:43 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5572 bytes)
16/10/26 17:13:43 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 8, localhost, partition 1, ANY, 5572 bytes)
16/10/26 17:13:43 INFO Executor: Running task 1.0 in stage 6.0 (TID 8)
16/10/26 17:13:43 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
16/10/26 17:13:43 INFO BlockManager: Found block rdd_23_0 locally
16/10/26 17:13:43 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 3418 bytes result sent to driver
16/10/26 17:13:43 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 16 ms on localhost (1/2)
16/10/26 17:13:43 INFO MemoryStore: Block rdd_23_1 stored as values in memory (estimated size 62.0 KB, free 366.0 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added rdd_23_1 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.1 MB)
16/10/26 17:13:43 INFO Executor: Finished task 1.0 in stage 6.0 (TID 8). 4653 bytes result sent to driver
16/10/26 17:13:43 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 8) in 97 ms on localhost (2/2)
16/10/26 17:13:43 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
16/10/26 17:13:43 INFO DAGScheduler: ResultStage 6 (treeAggregate at RowMatrix.scala:121) finished in 0.098 s
16/10/26 17:13:43 INFO DAGScheduler: Job 3 finished: treeAggregate at RowMatrix.scala:121, took 0.105681 s
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.1 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 9 from broadcast at RowMatrix.scala:439
16/10/26 17:13:43 INFO MapPartitionsRDD: Removing RDD 23 from persistence list
16/10/26 17:13:43 INFO BlockManager: Removing RDD 23
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.2 KB, free 366.1 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 270.0 B, free 366.1 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 130.49.212.215:53948 (size: 270.0 B, free: 366.3 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 10 from broadcast at RowMatrix.scala:439
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.8 KB, free 366.1 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.1 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 130.49.212.215:53948 in memory (size: 4.6 KB, free: 366.3 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.3 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 11 from broadcast at RowMatrix.scala:439
16/10/26 17:13:43 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 130.49.212.215:53948 in memory (size: 4.3 KB, free: 366.3 MB)
findmeee1
16/10/26 17:13:43 INFO SparkContext: Starting job: first at IndexedRowMatrix.scala:57
16/10/26 17:13:43 INFO DAGScheduler: Got job 4 (first at IndexedRowMatrix.scala:57) with 1 output partitions
16/10/26 17:13:43 INFO DAGScheduler: Final stage: ResultStage 8 (first at IndexedRowMatrix.scala:57)
16/10/26 17:13:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
16/10/26 17:13:43 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:43 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at map at IndexedRowMatrix.scala:184), which has no missing parents
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 10.3 KB, free 366.1 MB)
16/10/26 17:13:43 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.7 KB, free 366.1 MB)
16/10/26 17:13:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 130.49.212.215:53948 (size: 4.7 KB, free: 366.3 MB)
16/10/26 17:13:43 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at map at IndexedRowMatrix.scala:184)
16/10/26 17:13:43 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
16/10/26 17:13:43 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9, localhost, partition 0, ANY, 5660 bytes)
16/10/26 17:13:43 INFO Executor: Running task 0.0 in stage 8.0 (TID 9)
16/10/26 17:13:44 INFO MemoryStore: Block rdd_39_0 stored as values in memory (estimated size 62.0 KB, free 366.0 MB)
16/10/26 17:13:44 INFO BlockManagerInfo: Added rdd_39_0 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.2 MB)
16/10/26 17:13:44 WARN Executor: 1 block locks were not released by TID = 9:
[rdd_39_0]
16/10/26 17:13:44 INFO Executor: Finished task 0.0 in stage 8.0 (TID 9). 2624 bytes result sent to driver
16/10/26 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 548 ms on localhost (1/1)
16/10/26 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
16/10/26 17:13:44 INFO DAGScheduler: ResultStage 8 (first at IndexedRowMatrix.scala:57) finished in 0.549 s
16/10/26 17:13:44 INFO DAGScheduler: Job 4 finished: first at IndexedRowMatrix.scala:57, took 0.556782 s
16/10/26 17:13:44 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:121
16/10/26 17:13:44 INFO DAGScheduler: Got job 5 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
16/10/26 17:13:44 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
16/10/26 17:13:44 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:44 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at RowMatrix.scala:121), which has no missing parents
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 13.5 KB, free 366.0 MB)
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.1 KB, free 366.0 MB)
16/10/26 17:13:44 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 130.49.212.215:53948 (size: 5.1 KB, free: 366.2 MB)
16/10/26 17:13:44 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:44 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
16/10/26 17:13:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5668 bytes)
16/10/26 17:13:44 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 11, localhost, partition 1, ANY, 5668 bytes)
16/10/26 17:13:44 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
16/10/26 17:13:44 INFO Executor: Running task 1.0 in stage 10.0 (TID 11)
16/10/26 17:13:44 INFO BlockManager: Found block rdd_39_0 locally
16/10/26 17:13:44 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 3418 bytes result sent to driver
16/10/26 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 9 ms on localhost (1/2)
16/10/26 17:13:44 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 130.49.212.215:53948 in memory (size: 4.7 KB, free: 366.2 MB)
16/10/26 17:13:44 INFO MemoryStore: Block rdd_39_1 stored as values in memory (estimated size 62.0 KB, free 366.0 MB)
16/10/26 17:13:44 INFO BlockManagerInfo: Added rdd_39_1 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.1 MB)
16/10/26 17:13:44 INFO Executor: Finished task 1.0 in stage 10.0 (TID 11). 4726 bytes result sent to driver
16/10/26 17:13:44 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 11) in 544 ms on localhost (2/2)
16/10/26 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
16/10/26 17:13:44 INFO DAGScheduler: ResultStage 10 (treeAggregate at RowMatrix.scala:121) finished in 0.547 s
16/10/26 17:13:44 INFO DAGScheduler: Job 5 finished: treeAggregate at RowMatrix.scala:121, took 0.555979 s
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:13:44 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.1 MB)
16/10/26 17:13:44 INFO SparkContext: Created broadcast 14 from broadcast at RowMatrix.scala:439
16/10/26 17:13:44 INFO MapPartitionsRDD: Removing RDD 39 from persistence list
16/10/26 17:13:44 INFO BlockManager: Removing RDD 39
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.2 KB, free 366.1 MB)
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 270.0 B, free 366.1 MB)
16/10/26 17:13:44 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 130.49.212.215:53948 (size: 270.0 B, free: 366.3 MB)
16/10/26 17:13:44 INFO SparkContext: Created broadcast 15 from broadcast at RowMatrix.scala:439
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.8 KB, free 366.1 MB)
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.1 MB)
16/10/26 17:13:44 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.3 MB)
16/10/26 17:13:44 INFO SparkContext: Created broadcast 16 from broadcast at RowMatrix.scala:439
findmeee2
16/10/26 17:13:44 INFO SparkContext: Starting job: first at IndexedRowMatrix.scala:57
16/10/26 17:13:44 INFO DAGScheduler: Got job 6 (first at IndexedRowMatrix.scala:57) with 1 output partitions
16/10/26 17:13:44 INFO DAGScheduler: Final stage: ResultStage 12 (first at IndexedRowMatrix.scala:57)
16/10/26 17:13:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
16/10/26 17:13:44 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:44 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at map at IndexedRowMatrix.scala:184), which has no missing parents
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.7 KB, free 366.1 MB)
16/10/26 17:13:44 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.0 MB)
16/10/26 17:13:44 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 130.49.212.215:53948 (size: 5.2 KB, free: 366.2 MB)
16/10/26 17:13:44 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at map at IndexedRowMatrix.scala:184)
16/10/26 17:13:44 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
16/10/26 17:13:44 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, ANY, 5757 bytes)
16/10/26 17:13:44 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
16/10/26 17:13:45 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 130.49.212.215:53948 in memory (size: 5.1 KB, free: 366.3 MB)
16/10/26 17:13:48 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 62.0 KB, free 366.0 MB)
16/10/26 17:13:48 INFO BlockManagerInfo: Added rdd_55_0 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.2 MB)
16/10/26 17:13:48 WARN Executor: 1 block locks were not released by TID = 12:
[rdd_55_0]
16/10/26 17:13:48 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2624 bytes result sent to driver
16/10/26 17:13:48 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 3607 ms on localhost (1/1)
16/10/26 17:13:48 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
16/10/26 17:13:48 INFO DAGScheduler: ResultStage 12 (first at IndexedRowMatrix.scala:57) finished in 3.608 s
16/10/26 17:13:48 INFO DAGScheduler: Job 6 finished: first at IndexedRowMatrix.scala:57, took 3.613812 s
16/10/26 17:13:48 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:121
16/10/26 17:13:48 INFO DAGScheduler: Got job 7 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
16/10/26 17:13:48 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
16/10/26 17:13:48 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:48 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[58] at treeAggregate at RowMatrix.scala:121), which has no missing parents
16/10/26 17:13:48 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 14.9 KB, free 366.0 MB)
16/10/26 17:13:48 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.5 KB, free 366.0 MB)
16/10/26 17:13:48 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 130.49.212.215:53948 (size: 5.5 KB, free: 366.2 MB)
16/10/26 17:13:48 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[58] at treeAggregate at RowMatrix.scala:121)
16/10/26 17:13:48 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
16/10/26 17:13:48 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5765 bytes)
16/10/26 17:13:48 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 14, localhost, partition 1, ANY, 5765 bytes)
16/10/26 17:13:48 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
16/10/26 17:13:48 INFO Executor: Running task 1.0 in stage 14.0 (TID 14)
16/10/26 17:13:48 INFO BlockManager: Found block rdd_55_0 locally
16/10/26 17:13:48 INFO Executor: Finished task 0.0 in stage 14.0 (TID 13). 3331 bytes result sent to driver
16/10/26 17:13:48 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 13) in 11 ms on localhost (1/2)
16/10/26 17:13:52 INFO MemoryStore: Block rdd_55_1 stored as values in memory (estimated size 62.0 KB, free 365.9 MB)
16/10/26 17:13:52 INFO BlockManagerInfo: Added rdd_55_1 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.1 MB)
16/10/26 17:13:52 INFO Executor: Finished task 1.0 in stage 14.0 (TID 14). 4726 bytes result sent to driver
16/10/26 17:13:52 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 14) in 3538 ms on localhost (2/2)
16/10/26 17:13:52 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
16/10/26 17:13:52 INFO DAGScheduler: ResultStage 14 (treeAggregate at RowMatrix.scala:121) finished in 3.539 s
16/10/26 17:13:52 INFO DAGScheduler: Job 7 finished: treeAggregate at RowMatrix.scala:121, took 3.546060 s
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 365.9 MB)
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.8 KB, free 365.9 MB)
16/10/26 17:13:52 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.1 MB)
16/10/26 17:13:52 INFO SparkContext: Created broadcast 19 from broadcast at RowMatrix.scala:439
16/10/26 17:13:52 INFO MapPartitionsRDD: Removing RDD 55 from persistence list
16/10/26 17:13:52 INFO BlockManager: Removing RDD 55
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.2 KB, free 366.0 MB)
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 268.0 B, free 366.0 MB)
16/10/26 17:13:52 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 130.49.212.215:53948 (size: 268.0 B, free: 366.2 MB)
16/10/26 17:13:52 INFO SparkContext: Created broadcast 20 from broadcast at RowMatrix.scala:439
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:13:52 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.2 MB)
16/10/26 17:13:52 INFO SparkContext: Created broadcast 21 from broadcast at RowMatrix.scala:439
findmeee3
16/10/26 17:13:52 INFO SparkContext: Starting job: first at IndexedRowMatrix.scala:57
16/10/26 17:13:52 INFO DAGScheduler: Got job 8 (first at IndexedRowMatrix.scala:57) with 1 output partitions
16/10/26 17:13:52 INFO DAGScheduler: Final stage: ResultStage 16 (first at IndexedRowMatrix.scala:57)
16/10/26 17:13:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
16/10/26 17:13:52 INFO DAGScheduler: Missing parents: List()
16/10/26 17:13:52 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[71] at map at IndexedRowMatrix.scala:184), which has no missing parents
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 13.1 KB, free 366.0 MB)
16/10/26 17:13:52 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.6 KB, free 366.0 MB)
16/10/26 17:13:52 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 130.49.212.215:53948 (size: 5.6 KB, free: 366.2 MB)
16/10/26 17:13:52 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1012
16/10/26 17:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[71] at map at IndexedRowMatrix.scala:184)
16/10/26 17:13:52 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
16/10/26 17:13:52 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 15, localhost, partition 0, ANY, 5853 bytes)
16/10/26 17:13:52 INFO Executor: Running task 0.0 in stage 16.0 (TID 15)
16/10/26 17:13:53 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 130.49.212.215:53948 in memory (size: 5.5 KB, free: 366.2 MB)
16/10/26 17:13:53 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 130.49.212.215:53948 in memory (size: 5.2 KB, free: 366.2 MB)
16/10/26 17:13:53 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 130.49.212.215:53948 in memory (size: 2038.0 B, free: 366.2 MB)
16/10/26 17:14:45 INFO MemoryStore: Block rdd_71_0 stored as values in memory (estimated size 62.0 KB, free 366.0 MB)
16/10/26 17:14:45 INFO BlockManagerInfo: Added rdd_71_0 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.2 MB)
16/10/26 17:14:45 WARN Executor: 1 block locks were not released by TID = 15:
[rdd_71_0]
16/10/26 17:14:45 INFO Executor: Finished task 0.0 in stage 16.0 (TID 15). 2624 bytes result sent to driver
16/10/26 17:14:45 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 15) in 53630 ms on localhost (1/1)
16/10/26 17:14:45 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
16/10/26 17:14:45 INFO DAGScheduler: ResultStage 16 (first at IndexedRowMatrix.scala:57) finished in 53.630 s
16/10/26 17:14:45 INFO DAGScheduler: Job 8 finished: first at IndexedRowMatrix.scala:57, took 53.638411 s
16/10/26 17:14:45 INFO SparkContext: Starting job: treeAggregate at RowMatrix.scala:121
16/10/26 17:14:45 INFO DAGScheduler: Got job 9 (treeAggregate at RowMatrix.scala:121) with 2 output partitions
16/10/26 17:14:45 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at RowMatrix.scala:121)
16/10/26 17:14:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
16/10/26 17:14:45 INFO DAGScheduler: Missing parents: List()
16/10/26 17:14:45 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[74] at treeAggregate at RowMatrix.scala:121), which has no missing parents
16/10/26 17:14:45 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 130.49.212.215:53948 in memory (size: 5.6 KB, free: 366.2 MB)
16/10/26 17:14:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 16.3 KB, free 366.0 MB)
16/10/26 17:14:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.9 KB, free 366.0 MB)
16/10/26 17:14:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 130.49.212.215:53948 (size: 5.9 KB, free: 366.2 MB)
16/10/26 17:14:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1012
16/10/26 17:14:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[74] at treeAggregate at RowMatrix.scala:121)
16/10/26 17:14:45 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
16/10/26 17:14:45 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, localhost, partition 0, PROCESS_LOCAL, 5861 bytes)
16/10/26 17:14:45 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 17, localhost, partition 1, ANY, 5861 bytes)
16/10/26 17:14:45 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)
16/10/26 17:14:45 INFO Executor: Running task 1.0 in stage 18.0 (TID 17)
16/10/26 17:14:45 INFO BlockManager: Found block rdd_71_0 locally
16/10/26 17:14:45 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 3331 bytes result sent to driver
16/10/26 17:14:45 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 7 ms on localhost (1/2)
16/10/26 17:21:51 INFO MemoryStore: Block rdd_71_1 stored as values in memory (estimated size 62.0 KB, free 365.9 MB)
16/10/26 17:21:51 INFO BlockManagerInfo: Added rdd_71_1 in memory on 130.49.212.215:53948 (size: 62.0 KB, free: 366.1 MB)
16/10/26 17:21:51 INFO Executor: Finished task 1.0 in stage 18.0 (TID 17). 4726 bytes result sent to driver
16/10/26 17:21:51 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 17) in 426183 ms on localhost (2/2)
16/10/26 17:21:51 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
16/10/26 17:21:51 INFO DAGScheduler: ResultStage 18 (treeAggregate at RowMatrix.scala:121) finished in 426.184 s
16/10/26 17:21:51 INFO DAGScheduler: Job 9 finished: treeAggregate at RowMatrix.scala:121, took 426.229700 s
16/10/26 17:21:51 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 3.8 KB, free 365.9 MB)
16/10/26 17:21:51 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.8 KB, free 365.9 MB)
16/10/26 17:21:51 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.1 MB)
16/10/26 17:21:51 INFO SparkContext: Created broadcast 24 from broadcast at RowMatrix.scala:439
16/10/26 17:21:51 INFO MapPartitionsRDD: Removing RDD 71 from persistence list
16/10/26 17:21:51 INFO BlockManager: Removing RDD 71
16/10/26 17:21:51 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.2 KB, free 366.0 MB)
16/10/26 17:21:51 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 269.0 B, free 366.0 MB)
16/10/26 17:21:51 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 130.49.212.215:53948 (size: 269.0 B, free: 366.2 MB)
16/10/26 17:21:51 INFO SparkContext: Created broadcast 25 from broadcast at RowMatrix.scala:439
16/10/26 17:21:51 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:21:51 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.0 MB)
16/10/26 17:21:51 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 130.49.212.215:53948 (size: 3.8 KB, free: 366.2 MB)
16/10/26 17:21:51 INFO SparkContext: Created broadcast 26 from broadcast at RowMatrix.scala:439
findmeee4
16/10/26 17:21:52 INFO SparkContext: Starting job: first at IndexedRowMatrix.scala:57
16/10/26 17:21:52 INFO DAGScheduler: Got job 10 (first at IndexedRowMatrix.scala:57) with 1 output partitions
16/10/26 17:21:52 INFO DAGScheduler: Final stage: ResultStage 20 (first at IndexedRowMatrix.scala:57)
16/10/26 17:21:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
16/10/26 17:21:52 INFO DAGScheduler: Missing parents: List()
16/10/26 17:21:52 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[87] at map at IndexedRowMatrix.scala:184), which has no missing parents
16/10/26 17:21:52 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 14.5 KB, free 366.0 MB)
16/10/26 17:21:52 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 6.1 KB, free 366.0 MB)
16/10/26 17:21:52 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 130.49.212.215:53948 (size: 6.1 KB, free: 366.2 MB)
16/10/26 17:21:52 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1012
16/10/26 17:21:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[87] at map at IndexedRowMatrix.scala:184)
16/10/26 17:21:52 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
16/10/26 17:21:52 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 18, localhost, partition 0, ANY, 5949 bytes)
16/10/26 17:21:52 INFO Executor: Running task 0.0 in stage 20.0 (TID 18)
16/10/26 17:22:11 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 130.49.212.215:53948 in memory (size: 5.9 KB, free: 366.2 MB)
16/10/26 17:23:36 WARN BlockManager: Putting block rdd_87_0 failed
16/10/26 17:23:36 ERROR Executor: Exception in task 0.0 in stage 20.0 (TID 18)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:103)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:84)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:175)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:252)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:163)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:91)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
16/10/26 17:23:36 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:103)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:84)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:175)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:252)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:163)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:91)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
16/10/26 17:23:36 WARN TaskSetManager: Lost task 0.0 in stage 20.0 (TID 18, localhost): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:103)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:84)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:175)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:252)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:163)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:91)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)

16/10/26 17:23:36 INFO SparkContext: Invoking stop() from shutdown hook
16/10/26 17:23:36 ERROR TaskSetManager: Task 0 in stage 20.0 failed 1 times; aborting job
16/10/26 17:23:36 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
16/10/26 17:23:36 INFO TaskSchedulerImpl: Cancelling stage 20
16/10/26 17:23:36 INFO DAGScheduler: ResultStage 20 (first at IndexedRowMatrix.scala:57) failed in 104.267 s
16/10/26 17:23:36 INFO DAGScheduler: Job 10 failed: first at IndexedRowMatrix.scala:57, took 104.273032 s
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 20.0 failed 1 times, most recent failure: Lost task 0.0 in stage 20.0 (TID 18, localhost): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:103)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:84)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:175)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:252)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:163)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:91)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1305)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.take(RDD.scala:1279)
	at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1319)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.first(RDD.scala:1318)
	at org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix.numCols(IndexedRowMatrix.scala:57)
	at org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix.computeSVD(IndexedRowMatrix.scala:160)
	at Assign2$.main(a2.scala:62)
	at Assign2.main(a2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.mutable.ResizableArray$class.ensureSize(ResizableArray.scala:103)
	at scala.collection.mutable.ArrayBuffer.ensureSize(ArrayBuffer.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$eq(ArrayBuffer.scala:84)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:175)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:252)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:163)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:41)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:91)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
16/10/26 17:23:36 INFO SparkUI: Stopped Spark web UI at http://130.49.212.215:4041
16/10/26 17:23:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/10/26 17:23:36 INFO MemoryStore: MemoryStore cleared
16/10/26 17:23:36 INFO BlockManager: BlockManager stopped
16/10/26 17:23:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/10/26 17:23:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/10/26 17:23:36 INFO SparkContext: Successfully stopped SparkContext
16/10/26 17:23:36 INFO ShutdownHookManager: Shutdown hook called
16/10/26 17:23:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-eec5d6ad-4291-4396-a2ba-884229df8bdf
